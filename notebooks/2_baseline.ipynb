{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "sys.path.append('../src')\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from category_encoders import CatBoostEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_validate\n",
    "\n",
    "\n",
    "from sales_project.models import ClippingRegressor\n",
    "from sales_project.metrics import mean_cv_scores, evaluate\n",
    "from sales_project.utils import save_predictions, save_pkl, save_dict_as_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/artifacts/cleaned_data.csv', parse_dates=['date'])\n",
    "df_submission = df.query('is_submission == True')\n",
    "df = df.query('is_submission == False')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM. Kaggle RMSLE score: 0.67209"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"relative_sales\"\n",
    "num_cols = [\"transactions\", \"dcoilwtico\", \"onpromotion\"]\n",
    "cat_cols = [\"store_nbr\", \"family\", \"city\", \"state\", \"type\", \"cluster\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_pipeline(num_cols, cat_cols, min_value, max_value):\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        [\n",
    "            (\"num\", \"passthrough\", num_cols),\n",
    "            (\n",
    "                \"non-binary\",\n",
    "                CatBoostEncoder(cols=cat_cols),\n",
    "                cat_cols,\n",
    "            ),\n",
    "        ],\n",
    "        remainder=\"drop\",\n",
    "        verbose_feature_names_out=False,\n",
    "    )\n",
    "\n",
    "    model = ClippingRegressor(\n",
    "        base_estimator=LGBMRegressor(\n",
    "                verbose=-1,\n",
    "                n_jobs=-1,\n",
    "                random_state=42,\n",
    "        ),\n",
    "        min_value=min_value,\n",
    "        max_value=max_value,\n",
    "    )\n",
    "\n",
    "    pipeline = Pipeline(\n",
    "        [\n",
    "            (\"preprocessor\", preprocessor),\n",
    "            (\"model\", model),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model file saved at: ../models/baseline_lightgbm4.pkl\n",
      "csv file saved at: ../data/predictions/baseline_lightgbm4.csv\n"
     ]
    }
   ],
   "source": [
    "pipeline = init_pipeline(num_cols=num_cols, cat_cols=cat_cols, min_value=1e-8, max_value=df[target].max())\n",
    "pipeline.fit(df, df[target])\n",
    "save_pkl(model=pipeline, path=Path('../models/baseline_lightgbm4.pkl'))\n",
    "\n",
    "df_submission['sales'] = pipeline.predict(df_submission) * df_submission['median_sales_over_family']\n",
    "save_predictions(df_submission, filename='baseline_lightgbm4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON file saved at: ../scores/test_baseline_lightgbm4.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'MAE': 0.606148470768601,\n",
       " 'RMSE': 0.943270239761125,\n",
       " 'RMSLE': 0.3243373281527902,\n",
       " 'R2': 0.5817657581143305}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = init_pipeline(num_cols=num_cols, cat_cols=cat_cols, min_value=1e-8, max_value=df[target].max())\n",
    "pipeline.fit(df.query(\"subset == 'train'\"), df.query(\"subset == 'train'\")[target])\n",
    "\n",
    "y_pred = pipeline.predict(df.query(\"subset == 'test'\"))\n",
    "metrics = evaluate(df.query(\"subset == 'test'\")[target], y_pred)\n",
    "save_dict_as_json(data=metrics, path=Path('../scores/test_baseline_lightgbm4.json'))\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time=   9.5s\n",
      "[CV] END .................................................... total time=  11.5s\n",
      "[CV] END .................................................... total time=  13.6s\n",
      "[CV] END .................................................... total time=  11.5s\n",
      "[CV] END .................................................... total time=  12.4s\n",
      "JSON file saved at: ../scores/cv_baseline_lightgbm4.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fit_time': 11.3605,\n",
       " 'score_time': 0.3527,\n",
       " 'test_mean_absolute_error': 0.5822,\n",
       " 'test_root_mean_squared_error': 0.9468,\n",
       " 'test_root_mean_squared_log_error': 0.3464,\n",
       " 'test_r2': 0.5496}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tscv = TimeSeriesSplit(n_splits=5, test_size=int(0.1 * len(df.query(\"subset == 'train'\"))))\n",
    "\n",
    "cv_res = cross_validate(\n",
    "    pipeline,\n",
    "    df.query(\"subset == 'train'\"),\n",
    "    df.query(\"subset == 'train'\")[target],\n",
    "    cv=tscv,\n",
    "    n_jobs=1,\n",
    "    scoring=[\n",
    "        'neg_mean_absolute_error',\n",
    "        'neg_root_mean_squared_error',\n",
    "        'neg_root_mean_squared_log_error',\n",
    "        'r2',\n",
    "    ],\n",
    "    verbose=2\n",
    ")\n",
    "cv_res = mean_cv_scores(cv_res)\n",
    "save_dict_as_json(data=cv_res, path=Path('../scores/cv_baseline_lightgbm4.json'))\n",
    "cv_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost. Kaggle RMSLE score: 0.64114"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_pipeline(num_cols, cat_cols, min_value, max_value):\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        [\n",
    "            (\"num\", \"passthrough\", num_cols),\n",
    "            (\n",
    "                \"non-binary\",\n",
    "                CatBoostEncoder(cols=cat_cols),\n",
    "                cat_cols,\n",
    "            ),\n",
    "        ],\n",
    "        remainder=\"drop\",\n",
    "        verbose_feature_names_out=False,\n",
    "    )\n",
    "\n",
    "    model = ClippingRegressor(\n",
    "        XGBRegressor(\n",
    "            verbosity=0,\n",
    "            n_jobs=-1,\n",
    "            random_state=42,\n",
    "        ),\n",
    "        min_value=min_value,\n",
    "        max_value=max_value,\n",
    "    )\n",
    "\n",
    "    pipeline = Pipeline(\n",
    "        [\n",
    "            (\"preprocessor\", preprocessor),\n",
    "            (\"model\", model),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model file saved at: ../models/baseline_xgboost4.pkl\n",
      "csv file saved at: ../data/predictions/baseline_xgboost4.csv\n"
     ]
    }
   ],
   "source": [
    "pipeline = init_pipeline(num_cols=num_cols, cat_cols=cat_cols, min_value=1e-8, max_value=df[target].max())\n",
    "pipeline.fit(df, df[target])\n",
    "save_pkl(model=pipeline, path=Path('../models/baseline_xgboost4.pkl'))\n",
    "\n",
    "df_submission['sales'] = pipeline.predict(df_submission) * df_submission['median_sales_over_family']\n",
    "save_predictions(df_submission, filename='baseline_xgboost4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON file saved at: ../scores/test_baseline_xgboost4.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'MAE': 0.5744371597651557,\n",
       " 'RMSE': 0.8934911678901186,\n",
       " 'RMSLE': 0.31138630013050395,\n",
       " 'R2': 0.624743823493789}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = init_pipeline(num_cols=num_cols, cat_cols=cat_cols, min_value=1e-8, max_value=df[target].max())\n",
    "pipeline.fit(df.query(\"subset == 'train'\"), df.query(\"subset == 'train'\")[target])\n",
    "\n",
    "y_pred = pipeline.predict(df.query(\"subset == 'test'\"))\n",
    "metrics = evaluate(df.query(\"subset == 'test'\")[target], y_pred)\n",
    "save_dict_as_json(data=metrics, path=Path('../scores/test_baseline_xgboost4.json'))\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time=   8.6s\n",
      "[CV] END .................................................... total time=   7.7s\n",
      "[CV] END .................................................... total time=   9.0s\n",
      "[CV] END .................................................... total time=   9.9s\n",
      "[CV] END .................................................... total time=  11.2s\n",
      "JSON file saved at: ../scores/cv_baseline_xgboost4.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fit_time': 8.9555,\n",
       " 'score_time': 0.3054,\n",
       " 'test_mean_absolute_error': 0.5606,\n",
       " 'test_root_mean_squared_error': 0.9198,\n",
       " 'test_root_mean_squared_log_error': 0.3385,\n",
       " 'test_r2': 0.5738}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tscv = TimeSeriesSplit(n_splits=5, test_size=int(0.1 * len(df.query(\"subset == 'train'\"))))\n",
    "\n",
    "cv_res = cross_validate(\n",
    "    pipeline,\n",
    "    df.query(\"subset == 'train'\"),\n",
    "    df.query(\"subset == 'train'\")[target],\n",
    "    cv=tscv,\n",
    "    n_jobs=1,\n",
    "    scoring=[\n",
    "        'neg_mean_absolute_error',\n",
    "        'neg_root_mean_squared_error',\n",
    "        'neg_root_mean_squared_log_error',\n",
    "        'r2',\n",
    "    ],\n",
    "    verbose=2\n",
    ")\n",
    "cv_res = mean_cv_scores(cv_res)\n",
    "save_dict_as_json(data=cv_res, path=Path('../scores/cv_baseline_xgboost4.json'))\n",
    "cv_res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-24.06",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
